{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table {display: inline-block}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>table {display: inline-block}</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Austrian Housing Prices - Visualization and Advanced Regression Techniques</h1>\n",
    "<h4>by Arlin Gruber</h4></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " ### Goal\n",
    "The dataset contains 15 explanatory variables that describe a lot of aspects of residential homes in Austria. The data has been mined from a large Austrian property platform over the course of several weeks and contains 100.000 unique advertisements. Detailed information of how this was achieved is available [here](https://github.com/AReburg/Willhaben-Data-Mining). The overall goal is to predict the pricing of a given house/appartment based on the given dataset. The data is split into a train and test data set for me to train and test on. With this dataset the principles of stacking, blending and ensembling techniques shall be explored to predict accurate outcomes.\n",
    "\n",
    "\n",
    "\n",
    " **Table of Contents**\n",
    " \n",
    "1. [Installing/Loading Packages](#packages)\n",
    "    \n",
    "2. [Reading Data](#data)\n",
    "\n",
    "3. [Visualization](#visualization) \n",
    "\n",
    "4. [Data Preparation](#dataprep)\n",
    "\n",
    "5. [Geospatial Distribution across Austria](#geospatial_distribution) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"data\">Reading Data</a> \n",
    "The data (as previously mentioned) is split into a train and test file with both the features and target variable available in the train.csv file to train on and only the features (without the target variable) in the test set. \n",
    "Although I have loaded the files, it is still necessary to also load them in R, which takes a few seconds.   \n",
    "The data can be found in the db folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/PLZ_BESTIMMUNGSORT-20220629.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8500\\2476756986.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Burgenland'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'./data/PLZ_BESTIMMUNGSORT-20220629.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchardet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'./data/PLZ_BESTIMMUNGSORT-20220629.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/PLZ_BESTIMMUNGSORT-20220629.csv'"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import json\n",
    "import chardet  # ! pip install chardet\n",
    "\n",
    "def bundesland(k):\n",
    "    if k == 'Sa':\n",
    "        return 'Salzburg'\n",
    "    elif k == 'St':\n",
    "        return 'Steiermark'\n",
    "    elif k == 'W':\n",
    "        return 'Wien'\n",
    "    elif k == 'T':\n",
    "        return 'Tirol'\n",
    "    elif k == 'V':\n",
    "        return 'Vorarlberg'\n",
    "    elif k == 'K':\n",
    "        return 'Kärnten'\n",
    "    elif k == 'O':\n",
    "        return 'Oberösterreich'\n",
    "    elif k == 'N':\n",
    "        return 'Niederösterreich'\n",
    "    elif k == 'B':\n",
    "        return 'Burgenland'\n",
    "    \n",
    "with open(r'./data/PLZ_BESTIMMUNGSORT-20220629.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "tmp = pd.read_csv(r'./data/PLZ_BESTIMMUNGSORT-20220629.csv', sep=';', encoding=result['encoding'])\n",
    "tmp.rename(columns={'GEMNR': 'GKZ'}, inplace=True)\n",
    "print(f\"len: {tmp.shape[0]}, unique PLZ: {tmp.PLZ.nunique()}, duplicates: {tmp.duplicated('PLZ', keep=False).sum()}\")\n",
    "\n",
    "df2 = tmp.groupby(['PLZ'], as_index=False).agg({'PLZ':'first', 'Bestimmungsort':'first', 'OKZ':'first', 'Ortschaft':'first', 'GKZ':'first', 'GEMNAM': 'first'})\n",
    "print(f\"len: {df2.shape[0]}, unique PLZ: {df2.PLZ.nunique()}, duplicates: {df2.duplicated('PLZ', keep=False).sum()}\")\n",
    "\n",
    "with open(r'./data/PLZ_BESTIMMUNGSORT-20220629.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "plz = pd.read_csv(r'./data/PLZ_Verzeichnis-20220629.csv', sep=';', encoding=result['encoding'])\n",
    "plz['Bundesland'] = plz.apply(lambda x: bundesland(x.Bundesland), axis=1)\n",
    "#plz.rename(columns={'GEMNR': 'GKZ'}, inplace=True)\n",
    "print(f\"len: {plz.shape[0]}, unique PLZ: {plz.PLZ.nunique()}, duplicates: {plz.duplicated('PLZ', keep=False).sum()}\")\n",
    "plz.head(5)\n",
    "\n",
    "\n",
    "# get bezirk information\n",
    "with open(r'./data/counties_lookup.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "bezirk = pd.read_csv(r'./data/counties_lookup.csv', sep=';', encoding=result['encoding'])\n",
    "\n",
    "plz = plz.merge(bezirk[['PLZ','Bezirk']], on=['PLZ'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "ort = df2.merge(plz[['PLZ','Ort', 'Bundesland', 'Bezirk']], on=['PLZ'], how='left')\n",
    "print(f\"len: {ort.shape[0]}, unique PLZ: {ort.PLZ.nunique()}, duplicates: {ort.duplicated('PLZ', keep=False).sum()}\")\n",
    "\n",
    "ort.rename(columns={'PLZ': 'plz'}, inplace=True)\n",
    "#ort.head(15)\n",
    "\n",
    "with open(r'./data/data.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "\n",
    "dfx = pd.read_csv('./data/data.csv', encoding=result['encoding'])\n",
    "dfx.rename(columns={'living_area':'area'}, inplace=True)\n",
    "# dfx['code'] = dfx['code'].fillna(0).astype(\"int\")\n",
    "dfx['plz'] = dfx.plz.fillna(0).astype(\"int64\")\n",
    "#dfx['url_rank'] = dfx.url_rank.fillna(0).astype(\"int64\")\n",
    "#dfx['GKZ'] = dfx.GKZ.fillna(0).astype(\"int64\")\n",
    "#dfx = df.dropna(subset=['price', 'area'])\n",
    "#dfx.type.value_counts()\n",
    "dfx.head()\n",
    "\n",
    "\n",
    "# merge with iso geoinformation\n",
    "\n",
    "df = dfx.merge(ort[['plz','GKZ', 'Ort', 'Bundesland', 'Bezirk']], on=['plz'], how='left')\n",
    "#df['code'] = df['code'].astype(\"category\")\n",
    "df['plz'] = df['plz'].astype(\"category\")\n",
    "df['GKZ'] = df.GKZ.fillna(0).astype(\"int64\")\n",
    "df['GKZ'] = df['GKZ'].astype(\"category\")\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', infer_datetime_format=True)\n",
    "df.sort_values(by='date', ascending = True, inplace=True)\n",
    "df.dropna(subset=['Bundesland'], axis=0, inplace=True)\n",
    "ort.head()\n",
    "\n",
    "#df[df['code'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.to_csv('data_fin.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"visualization\">Visualization</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(df, category='rented flat'):\n",
    "    fig = px.scatter(df[(df['type'] ==category) &  (df['area'] >0) & #(df['price'] <=5000)&\n",
    "                        (df['area'] <=350)], x=\"area\", y=\"price\")\n",
    "    fig.update_layout(width=800, height=400,\n",
    "            title_text=format_title(\"Price per living area\", f\"Rented flat\"),\n",
    "            font=dict(family=\"Open Sans\")\n",
    "            )\n",
    "    fig.show()\n",
    "explore(df, category='rented flat')\n",
    "explore(df, category='condominium')\n",
    "explore(df, category='single-family home') \n",
    "\n",
    "\n",
    "#condominium single-family home\n",
    "#print(df[(df['type'] =='rented flat') & (df['price'] <=5000) & (df['living_area'] >0)& (df['living_area'] <=350)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df = df[((df['type'] == 'rented flat') & (df['price'] <8000) & (df['price'] >100))\n",
    "       | ((df['type'] == 'condominium') & (df['price'] <4000000) & (df['price'] >30000))\n",
    "       | ((df['type'] == 'single-family home') & (df['price'] <4000000) & (df['price'] >30000)& (df['area'] >10))]\n",
    "explore(df, category='rented flat')\n",
    "explore(df, category='condominium')\n",
    "explore(df, category='single-family home') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rooms'].value_counts().head(10)\n",
    "df.type.value_counts()\n",
    "print(f\"The data set has unique adverisements: {df.code.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the target variable \"SalePrice\" has a skewed distribution. Because I will be predicting a continuous feature, I will be using regressors which perform better if the target variable has a normal distribution with little to no skewdness. Thus, it is important to remember that in a later stage the data needs to be normalized.\n",
    "### <a name=\"Data Preperation\">Data Preperation and Feature Extraction</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions help us to count the appearance in the aggregated data and to caluclate the ratio of the properties where a real estate agency is selling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_comm(raw):\n",
    "    if len(raw.value_counts()) < 2:\n",
    "        # With commission -> 100% real estate agency selling\n",
    "        if raw.value_counts().index.tolist()[0] == True:\n",
    "            return 1\n",
    "        # No commission\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        # eq: broker comm./(broker comm. + no broker comm.)\n",
    "        return round(raw.value_counts().sort_index(ascending=False)[1]/\n",
    "                     (raw.value_counts().sort_index(ascending=False)[0]+raw.value_counts().sort_index(ascending=False)[1]), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_data(selector):\n",
    "    # Load Austrian geojson \n",
    "    if selector == 'municipal':\n",
    "        link = 'https://raw.githubusercontent.com/ginseng666/GeoJSON-TopoJSON-Austria/master/2021/simplified-99.5/gemeinden_995_geo.json'\n",
    "\n",
    "    elif selector == 'district':\n",
    "            link = 'https://raw.githubusercontent.com/ginseng666/GeoJSON-TopoJSON-Austria/master/2021/simplified-99.9/bezirke_999_geo.json'\n",
    "            \n",
    "        \n",
    "    elif selector == 'state':\n",
    "        link = 'https://raw.githubusercontent.com/ginseng666/GeoJSON-TopoJSON-Austria/master/2021/simplified-99.9/laender_999_geo.json'\n",
    "   \n",
    "    with urlopen(link) as response:\n",
    "        counties = json.load(response)\n",
    "        \n",
    "    return counties\n",
    "\n",
    "\n",
    "def format_title(title, subtitle=None, subtitle_font_size=14):\n",
    "        \"\"\"        \"\"\"\n",
    "        title = f'<b>{title}</b>'\n",
    "        if not subtitle:\n",
    "            return title\n",
    "        subtitle = f'<span style=\"font-size: {subtitle_font_size}px;\">{subtitle}</span>'\n",
    "        return f'{title}<br>{subtitle}'\n",
    "\n",
    "    \n",
    "def geo_heatmap(df, selector='state', housing_category='rented flat'):\n",
    "    \"\"\" selector specifies the geographic resolution \"\"\"\n",
    "    df['count'] = np.nan\n",
    "    feat_key = ''\n",
    "    locations = ''\n",
    "    hover_data = ''\n",
    "    opacity = 0.95\n",
    "    title = ''\n",
    "    category = ''\n",
    "    if housing_category == 'rented flat':\n",
    "        df.type.head()\n",
    "        df = df[(df['type'].str.contains('rented flat', na = False)) & (df['rooms'] < 6)].copy()\n",
    "        category = 'rented flat'\n",
    "    elif housing_category == 'condominium':\n",
    "        df.type.head()\n",
    "        df = df[(df['type'].str.contains('condominium', na = False))].copy()\n",
    "        category = 'condominium'\n",
    "    elif housing_category == 'single-family home':\n",
    "        df.type.head()\n",
    "        df = df[(df['type'].str.contains('single-family home', na = False))].copy()\n",
    "        category = 'single-family home'\n",
    "        # df2.sort_values(\"price_sqrt\", ascending=False)\n",
    "        # df4.loc[df4.commission.isna()==True,'price_sqrt'] =1\n",
    "\n",
    "    if selector == 'municipal':\n",
    "        feat_key = \"properties.iso\"\n",
    "        locations = \"GKZ\"\n",
    "        hover_data = [\"GKZ\", \"Bezirk\", \"Bundesland\", \"count\"]\n",
    "        hover_name = \"GKZ\"\n",
    "        title = [\"Austrian Housing Market\", f\"{category} prices on municipal level\"]\n",
    "        dfx = df.groupby(['GKZ'], as_index=False).agg({'price': 'mean', 'price_sqrt': 'mean', 'Bezirk': 'first', 'Bundesland': 'first', 'commission':calc_comm, 'count':'size'})\n",
    "\n",
    "    elif selector == 'district':\n",
    "        feat_key = \"properties.name\"\n",
    "        locations = \"Bezirk\"\n",
    "        hover_data = [\"Bundesland\", \"Bezirk\", \"count\"]\n",
    "        hover_name = \"Bezirk\"\n",
    "        opacity = 0.65\n",
    "        dfx = df.groupby(['Bezirk'], as_index=False).agg({'price':'mean', 'price_sqrt':'mean', 'Bundesland':'first', 'commission':calc_comm, 'count':'size'})\n",
    "        title = [\"Austrian Housing Market\", f\"{category} prices on district level\"]\n",
    "    \n",
    "    elif selector == 'state':\n",
    "        feat_key = \"properties.name\"\n",
    "        locations = \"Bundesland\"\n",
    "        hover_data = [\"Bundesland\", \"count\"]\n",
    "        hover_name = \"Bundesland\"\n",
    "        opacity = 0.65\n",
    "        title = [\"Austrian Housing Market\", f\"{category} prices on state level\"]\n",
    "        dfx = df.groupby(['Bundesland'], as_index=False).agg({'price':'mean', 'price_sqrt':'median', 'commission':calc_comm, 'count':'size'})\n",
    "\n",
    "    fig = px.choropleth_mapbox(dfx, geojson=get_geo_data(selector), locations=locations,\n",
    "                               featureidkey=feat_key, color=\"price_sqrt\",\n",
    "                               color_continuous_scale=\"Viridis\",\n",
    "                               range_color=(df['price_sqrt'].quantile(0.25), df['price_sqrt'].quantile(0.75)),\n",
    "                               mapbox_style=\"open-street-map\",\n",
    "                               hover_data = hover_data,\n",
    "                               hover_name = hover_name,\n",
    "                               #mapbox_style=\"carto-positron\",\n",
    "                               zoom=6, center = {\"lat\": 47.809490, \"lon\": 13.055010},\n",
    "                               opacity=opacity,\n",
    "                              )\n",
    "    \n",
    "    fig.update_layout(width=1000, height=600,\n",
    "            title_text=format_title(title[0], f\"{title[1]}\"),\n",
    "            font=dict(family=\"Open Sans\"),\n",
    "            coloraxis_colorbar_title='€/m²'\n",
    "            )\n",
    "    fig.update_layout(margin={\"r\":30,\"t\":60,\"l\":30,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aber = df.date.unique().tolist()\n",
    "#print(a)\n",
    "from datetime import datetime\n",
    "k = [print(int(i)) for i in aber]\n",
    "k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### <a name=\"geospatial_distribution\">Geospatial distribution</a> \n",
    "In the following section I will analyze how property prices are distributed accross Austria. The data set includes several categories such as price per m², area code as well as categories such as broker commission, garden, balcony, elevator, cellar or whether a garage is present. All the rows where no price has been specified are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section I will analyze how property prices are distributed accross Austria. The data set includes several categories such as price per m², the municipal, state, district level as well as categories such as broker commission, garden, balcony, elevator, cellar or garage present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier are removed from the data set. Only rented flats with up to 5 rooms are considered moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to map the data to a geographic area the geo json data needs to be imported:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three geospatial heatmaps depict the real estate prices on a state, district and municipal level. The following heat map shows the real estate prices on a state level. The median prices per m² of rental property are the highest in Tyrol followed by Vorarlberg, Vienna and Salzburg. Vorarlberg however, has only a total of 94 advertisements and might be overrepresented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_heatmap(df, 'state', 'rented flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_heatmap(df, 'district', 'single-family home') #condominium single-family home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_heatmap(df, 'municipal', 'condominium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_heatmap(df, 'municipal', 'rented flat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down the geographical structure to the municipal level confirms that even the picture painted on district level\n",
    "should be perceived with great care. For example, the district \"Bludenz\" accounts for a large area and has just one data entry (cc is 80405). The situation is similar for the rest of Tyrol which is very underrepresented sample wise compared to the rest of Austria. For some of the districts it is difficult to draw a conclusion since the sample size is very low. \n",
    "One example would be Bludenz with just a couple of rental properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: What attributes contributing to a higher condo price the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_f = df.drop(['CC', 'PG', 'price'], axis=1)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "cor = df_f.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target = abs(cor['price_sqrt'])#Selecting correlated features\n",
    "cor_target[cor_target>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target = abs(cor['rooms'])\n",
    "cor_target[cor_target>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target = abs(cor['cellar'])\n",
    "cor_target[cor_target>0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it is difficult to draw conclusions regarding certain factors contributing to the rental price of a flat. From the correlation matrix it is obvious that the number of rooms is highly correlated to the living area. Flats with a cellar are more likely to have an elevator and a garage or parking lot. However these are still very weak correlation and needs to be further investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is the price changing for the advertisements?\n",
    "It is interesting to know, how the propery and rental prices are changing over the live time of the advertisement.\n",
    "First, the number of occourances of each advertisement is calculated.\n",
    "Afterwards the data set is aggregated indicating us the *first* and the *last* **date** and **price** of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df.groupby(['code']).agg({'code': ['first', 'size'], 'price': ['first', 'last'], 'url_rank': ['first','mean','last'], 'date': ['first', 'last'], 'type': ['first'], 'commission': ['first']})\n",
    "df7.columns = df7.columns.droplevel(0)\n",
    "df7.columns = ['code', 'occ.', 'p.first', 'p.last', 'r.first', 'r.mean','r.last', 'dt.first', 'dt.last', 'type','commission']\n",
    "df7['online'] = (df7['dt.last']-df7['dt.first']).dt.days\n",
    "df7['pdiff'] =  df7['p.last']-df7['p.first']\n",
    "df7 = df7.reset_index(drop=True)\n",
    "df7.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df7.copy()\n",
    "df8 = df8.dropna(subset=['p.last'])\n",
    "df8 = df8[(df8['p.last'] != 0)]\n",
    "# df8 = df8[(df8['type']=='rented flat') & (np.absolute(df8.pdiff) < 600)]\n",
    "val=df8[df8['pdiff'] != 0]['pdiff'].mean()\n",
    "\n",
    "print(f'Avg. price change since initial offering: {round(val)} €')\n",
    "print(f\"{df8[df8['pdiff'] != 0].shape[0]}, {df8.shape[0]}\")\n",
    "df8.reset_index(drop=True, inplace=True)\n",
    "df8[df8['pdiff'] != 0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df8[df8['pdiff'] != 0], x=\"online\", y=\"pdiff\", color=\"type\",\n",
    "                  hover_data=['type', 'occ.'], width=600, height=400) #size='occ.',\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: What are the chances of getting a condo without a real estate agency?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Roughly {100 *round(df7.commission.value_counts()[1]/df7.shape[0],3)}% of the flats/houses can only be rented/purchased from a real eastate agency.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 85,000 properties in the data set only 16.7% are without a real estate agency. It will be interesting to track this value over time since the Austrian goverment changed a law regarding the real estate agancy fee structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Is it possible to identify paid upgrades in the ads?\n",
    "In case an advertisement is older but still on the first pages it is identified as a paid upgrade. This are the conditions that need to be met in order to be classified as such:\n",
    "- if the advertisement is online for an extended period of time (one week)\n",
    "- AND the mean ranking is below a threshold of 10\n",
    "\n",
    "According to the [willhaben website](www.willhaben.at) this is the current pricing model for the real estate section. There are additional models available for other topics such as jobs, goods and services, cars etc.\n",
    "\n",
    "\n",
    "| product   | price | expiration |\n",
    "|-----------|-------|------------|\n",
    "| ad sell flat | 39 €  | 30 days    |\n",
    "| ad rent flat | 29 €  | 30 days    |\n",
    "\n",
    "\n",
    "\n",
    "Additionally the following upgrades can be purchased:\n",
    "\n",
    "| upgrade                | price   | expiration   |\n",
    "|------------------------|---------|--------------|\n",
    "| re-rank ad to beginning   | 27.90 € | 4 weeks      |\n",
    "| highlight ad. by color | 17.90 € | once per ad. |\n",
    "\n",
    "\n",
    "To calculate the total revenue in the housing section (since 2022-06-06; altough the infrastructure was initially not in place to get the whole picture) is estimated with the following equations:\n",
    "1) $R_{housing}=R_{rental}+R_{real estate}$\n",
    "\n",
    "2) $R_{flat}=c_{flat}*p_{ad,flat} + c_{upgrades}*p_{upgrade}$\n",
    "\n",
    "3) $R_{house}=c_{house}*p_{ad,house} + c_{upgrades}*p_{upgrade}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pricing model\n",
    "price_ad_rent = 29\n",
    "price_ad_house = 39\n",
    "price_ad_upgrade = 27.90\n",
    "\n",
    "df6 = df7.copy()\n",
    "\n",
    "df6 = df6[(df6['online']>7) & (df6['r.mean']<100)]\n",
    "df6.sort_values(by='dt.last', ascending = False, inplace=True)\n",
    "num_upgr_ads_flat= df6[df6['type']=='rented flat'].shape[0]\n",
    "num_upgr_ads_house= df6[df6['type']=='condominium'].shape[0] + df6[df6['type']=='single-family home'].shape[0]\n",
    "num_paid_ads= df6.shape[0]\n",
    "\n",
    "print(f'Since 2022-06-10:\\n{num_paid_ads} unique housing ads total\\n{num_upgr_ads_flat} customers paid for the flat upgrade\\n{num_upgr_ads_house} customers paid for the housing upgrade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.sort_values(by='dt.first', ascending=True, inplace=True)\n",
    "rent_flat = df7[(df7.type == 'rented flat')]['code'].shape[0]\n",
    "house = df7[(df7.type == 'condominium') | (df7.type == 'single-family home')]['code'].shape[0]\n",
    "\n",
    "sume = rent_flat*price_ad_rent+house*price_ad_house\n",
    "f2_exp = df7[(df7['online']> 30) & (df7.type == 'rented flat')]['code'].shape[0]\n",
    "h2_exp = df7[(df7['online']> 30) & ((df7.type == 'condominium') | (df7.type == 'single-family home'))]['code'].shape[0]\n",
    "print(f\"Since 2022-06-10:\")\n",
    "print(f\"Unique flats: {rent_flat}, unique appartments/houses: {house}\")\n",
    "print(f\"Ad revenue generated: {sume} €\")\n",
    "print(f\"Additional revenue durch verlängern inserat: {f2_exp*price_ad_rent+ h2_exp*price_ad_house} €\")\n",
    "print(f\"Sum: {sume+ f2_exp*price_ad_rent+ h2_exp*price_ad_house} €\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part V: How many new ads are appearing on the platform per week?¶\n",
    "\n",
    "How many advertisments are in a given interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules/libraries\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore')\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import time\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import geojson\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "import chardet\n",
    "from scipy import spatial\n",
    "from scipy.spatial import KDTree\n",
    "from shapely import wkt\n",
    "\n",
    "cwd = Path().resolve()\n",
    "\n",
    "# visualisation\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>iso</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tirol</td>\n",
       "      <td>7</td>\n",
       "      <td>MULTIPOLYGON (((12.70891 46.73637, 12.68781 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vorarlberg</td>\n",
       "      <td>8</td>\n",
       "      <td>MULTIPOLYGON (((10.13171 47.03008, 10.15697 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wien</td>\n",
       "      <td>9</td>\n",
       "      <td>MULTIPOLYGON (((16.36286 48.12937, 16.30943 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burgenland</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((16.06293 46.85060, 15.99344 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kärnten</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTIPOLYGON (((14.43169 46.44365, 14.30534 46...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name iso                                           geometry\n",
       "0       Tirol   7  MULTIPOLYGON (((12.70891 46.73637, 12.68781 46...\n",
       "1  Vorarlberg   8  MULTIPOLYGON (((10.13171 47.03008, 10.15697 46...\n",
       "2        Wien   9  MULTIPOLYGON (((16.36286 48.12937, 16.30943 48...\n",
       "3  Burgenland   1  MULTIPOLYGON (((16.06293 46.85060, 15.99344 46...\n",
       "4     Kärnten   2  MULTIPOLYGON (((14.43169 46.44365, 14.30534 46..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file(os.path.join(Path(cwd).parent, 'data', 'geojson', 'laender_999_geo.json'))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path = Path(os.path.join(Path(cwd).parent, 'data', 'osm', 'Burgenland_water.csv'))\n",
    "path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 187 s\n",
      "Completed in 20 s\n",
      "Completed in 7 s\n",
      "Completed in 28 s\n",
      "Completed in 30 s\n",
      "Completed in 69 s\n",
      "Completed in 50 s\n",
      "Completed in 31 s\n",
      "Completed in 55 s\n"
     ]
    }
   ],
   "source": [
    "def get_osm_data(region, name, data):\n",
    "    df = ox.geometries.geometries_from_polygon(region, tags=data[0])\n",
    "    df.to_csv(os.path.join(Path(cwd).parent, 'data', 'osm', \n",
    "                           f'{name}_{list(data[0].values())[0]}.csv'), columns=['geometry'])\n",
    "    return df\n",
    "\n",
    "\n",
    "for index, row in gdf.iterrows():\n",
    "    region = row['geometry']#.unary_union\n",
    "    t0 = time.time()\n",
    "    water = get_osm_data(region, row['name'], [{'natural':'water'}])\n",
    "    #forest = ox.geometries.geometries_from_polygon(region, tags = {'landuse': 'forest'})\n",
    "    #rivers = ox.geometries.geometries_from_polygon(region, tags = {'waterway': 'river'})\n",
    "    print (f\"Completed in {round(time.time() - t0)} s\")\n",
    "\n",
    "#boundary_geojson.drop(columns=['cartodb_id', 'created_at', 'updated_at'], inplace=True)\n",
    "#region = boundary_geojson.geometry.unary_union\n",
    "#region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>iso</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tirol</td>\n",
       "      <td>7</td>\n",
       "      <td>MULTIPOLYGON (((12.70891 46.73637, 12.68781 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vorarlberg</td>\n",
       "      <td>8</td>\n",
       "      <td>MULTIPOLYGON (((10.13171 47.03008, 10.15697 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wien</td>\n",
       "      <td>9</td>\n",
       "      <td>MULTIPOLYGON (((16.36286 48.12937, 16.30943 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burgenland</td>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((16.06293 46.85060, 15.99344 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kärnten</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTIPOLYGON (((14.43169 46.44365, 14.30534 46...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name iso                                           geometry\n",
       "0       Tirol   7  MULTIPOLYGON (((12.70891 46.73637, 12.68781 46...\n",
       "1  Vorarlberg   8  MULTIPOLYGON (((10.13171 47.03008, 10.15697 46...\n",
       "2        Wien   9  MULTIPOLYGON (((16.36286 48.12937, 16.30943 48...\n",
       "3  Burgenland   1  MULTIPOLYGON (((16.06293 46.85060, 15.99344 46...\n",
       "4     Kärnten   2  MULTIPOLYGON (((14.43169 46.44365, 14.30534 46..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
